# Word2vec_tutorials
The way I learnt word2vec. I suggest to read in the same order the references are put across.

# Jay Alammar's non-technical introduction to word2vec
http://jalammar.github.io/illustrated-word2vec/
This is the best word2vec 101 I have come across. One gets to learn word2vec with very little understanding of the machine learning/complexities underneath

# Chris McCormick's indepth tutorial on word2vec (skipgram only)
http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
Shows the math underneath in a minimalistic yet in practical way

# Detailed explanation on Word embeddings (Super Technical)
http://ruder.io/word-embeddings-1/index.html
Sebastian Ruder does a detailed walk through and covers the variations

# Google's trained Word2Vec model in Python
http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/


# Word2vec for Advertisement and Recommender systems
http://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/

# word2vec applied in Song/Playlist recommendation system
https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484

# word2vec in searching similarity and ranking
https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e

# Word2vec original paper
1. Efficient Estimation of Word Representations in
Vector Space : https://arxiv.org/pdf/1301.3781.pdf
2. Distributed Representations of Words and Phrases
and their Compositionality : https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
3. Original Nueral Probabilistic Language Model by Bengio: http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf

